<?xml version="1.0"?>
<records xmlns="http://scientific.thomsonreuters.com/schema/wok5.4/public/Fields"><REC r_id_disclaimer="ResearcherID data provided by Clarivate Analytics"><UID>WOS:000452864500004</UID><static_data><fullrecord_metadata><fund_ack><grants count="4"><grant><grant_agency>U.S. Department of Energy</grant_agency><grant_ids count="1"><grant_id>DE-AC05-00OR22725</grant_id></grant_ids></grant><grant><grant_agency>Reducing Uncertainties in Biogeochemical Interactions through Synthesis and Computation Scientific Focus Area (RUBISCO SFA)</grant_agency></grant><grant><grant_agency>Regional and Global Climate Modeling (RGCM) Program in the Climate and Environmental Sciences Division (CESD) of the Office of Biological and Environmental Research (BER) in the U.S. Department of Energy Office of Science</grant_agency></grant><grant><grant_agency/><grant_ids count="1"><grant_id>DE-AC02-05CH11231</grant_id></grant_ids></grant></grants></fund_ack><abstracts count="1"><abstract><abstract_text count="1"><p>The increasing complexity of Earth system models has inspired efforts to quantitatively assess model fidelity through rigorous comparison with best available measurements and observational data products. Earth system models exhibit a high degree of spread in predictions of land biogeochemistry, biogeophysics, and hydrology, which are sensitive to forcing from other model components. Based on insights from prior land model evaluation studies and community workshops, the authors developed an open source model benchmarking software package that generates graphical diagnostics and scores model performance in support of the International Land Model Benchmarking (ILAMB) project. Employing a suite of in situ, remote sensing, and reanalysis data sets, the ILAMB package performs comprehensive model assessment across a wide range of land variables and generates a hierarchical set of web pages containing statistical analyses and figures designed to provide the user insights into strengths and weaknesses of multiple models or model versions. Described here is the benchmarking philosophy and mathematical methodology embodied in the most recent implementation of the ILAMB package. Comparison methods unique to a few specific data sets are presented, and guidelines for configuring an ILAMB analysis and interpreting resulting model performance scores are discussed. ILAMB is being adopted by modeling teams and centers during model development and for model intercomparison projects, and community engagement is sought for extending evaluation metrics and adding new observational data sets to the benchmarking framework.</p></abstract_text></abstract></abstracts></fullrecord_metadata></static_data><dynamic_data><cluster_related/></dynamic_data></REC></records>
