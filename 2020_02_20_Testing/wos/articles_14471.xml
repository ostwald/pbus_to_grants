<?xml version="1.0"?>
<records xmlns="http://scientific.thomsonreuters.com/schema/wok5.4/public/Fields"><REC r_id_disclaimer="ResearcherID data provided by Clarivate Analytics"><UID>WOS:000344597000023</UID><static_data><fullrecord_metadata><fund_ack><grants count="2"><grant><grant_agency>Regional and Global Climate Modeling Program (RGCM) of the US Department of Energy's Office of Biological &amp; Environmental Research (BER)</grant_agency><grant_ids count="1"><grant_id>DE-FC02-97ER62402</grant_id></grant_ids></grant><grant><grant_agency>National Science Foundation</grant_agency></grant></grants></fund_ack><abstracts count="1"><abstract><abstract_text count="1"><p>The slowdown in the rate of global warming in the early 2000s is not evident in the multi-model ensemble average of traditional climate change projection simulations1. However, a number of individual ensemble members from that set of models successfully simulate the early-2000s hiatus when naturally-occurring climate variability involving the Interdecadal Pacific Oscillation (IPO) coincided, by chance, with the observed negative phase of the IPO that contributed to the early-2000s hiatus. If the recent methodology of initialized decadal climate prediction could have been applied in the mid-1990s using the Coupled Model Intercomparison Project Phase 5 multi-models, both the negative phase of the IPO in the early 2000s as well as the hiatus could have been simulated, with the multi-model average performing better than most of the individual models. The loss of predictive skill for six initial years before the mid-1990s points to the need for consistent hindcast skill to establish reliability of an operational decadal climate prediction system.</p></abstract_text></abstract></abstracts></fullrecord_metadata></static_data><dynamic_data><cluster_related/></dynamic_data></REC></records>
